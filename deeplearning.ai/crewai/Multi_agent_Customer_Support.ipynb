{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "SetTN1icr-s5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wVrbjhssq0qz",
        "outputId": "b21408a4-0331-4bbd-c657-0b818ef0450e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crewai==0.28.8 in /usr/local/lib/python3.11/dist-packages (0.28.8)\n",
            "Requirement already satisfied: crewai_tools==0.1.6 in /usr/local/lib/python3.11/dist-packages (0.1.6)\n",
            "Requirement already satisfied: langchain_community==0.0.29 in /usr/local/lib/python3.11/dist-packages (0.0.29)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (1.0.4)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.4.4)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (8.1.7)\n",
            "Requirement already satisfied: embedchain<0.2.0,>=0.1.98 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (0.1.113)\n",
            "Requirement already satisfied: instructor<0.6.0,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (0.5.2)\n",
            "Requirement already satisfied: langchain<0.2.0,>=0.1.10 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (0.1.13)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.93.0)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.27.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.0.0)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.12.25 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (2023.12.25)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (4.13.4)\n",
            "Requirement already satisfied: chromadb<0.5.0,>=0.4.22 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (0.4.24)\n",
            "Requirement already satisfied: lancedb<0.6.0,>=0.5.4 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (0.5.7)\n",
            "Requirement already satisfied: pyright<2.0.0,>=1.1.350 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (1.1.402)\n",
            "Requirement already satisfied: pytest<9.0.0,>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (8.3.5)\n",
            "Requirement already satisfied: pytube<16.0.0,>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (15.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (2.32.3)\n",
            "Requirement already satisfied: selenium<5.0.0,>=4.18.1 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (4.34.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (0.1.53)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (1.26.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (8.5.0)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.20.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (4.14.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.115.14)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.35.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.25.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.7.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48b0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.73.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.9.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (33.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.10.18)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (0.9.0)\n",
            "Requirement already satisfied: alembic<2.0.0,>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.16.2)\n",
            "Requirement already satisfied: clarifai<11.0.0,>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (10.11.1)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.100.0)\n",
            "Requirement already satisfied: gptcache<0.2.0,>=0.1.43 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.44)\n",
            "Requirement already satisfied: langchain-cohere<0.2.0,>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.5)\n",
            "Requirement already satisfied: langchain-openai<0.2.0,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.7)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.3.1)\n",
            "Requirement already satisfied: pysbd<0.4.0,>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.3.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.9.4)\n",
            "Requirement already satisfied: schema<0.8.0,>=0.7.5 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.7.5)\n",
            "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.7.0)\n",
            "Requirement already satisfied: PyGithub<2.0.0,>=1.59.1 in /usr/local/lib/python3.11/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.59.1)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.38 in /usr/local/lib/python3.11/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.1.44)\n",
            "Requirement already satisfied: youtube-transcript-api<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (0.6.3)\n",
            "Requirement already satisfied: yt_dlp<2024.0.0,>=2023.11.14 in /usr/local/lib/python3.11/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2023.12.30)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.174.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.25.8)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /usr/local/lib/python3.11/dist-packages (from instructor<0.6.0,>=0.5.2->crewai==0.28.8) (0.15)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (2.1.0)\n",
            "Requirement already satisfied: pylance==0.9.18 in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (0.9.18)\n",
            "Requirement already satisfied: ratelimiter~=1.0 in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (1.2.0.post0)\n",
            "Requirement already satisfied: retry>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (0.9.2)\n",
            "Requirement already satisfied: semver>=3.0 in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (3.0.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.5.2)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.11/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (18.1.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (1.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (0.0.2)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29) (23.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.28.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8) (0.48b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.4.1)\n",
            "Requirement already satisfied: nodeenv>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6) (1.9.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2025.6.15)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (0.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.2.3)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.1.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.0)\n",
            "Requirement already satisfied: clarifai-grpc>=10.11.2 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (11.5.5)\n",
            "Requirement already satisfied: clarifai-protocol>=0.0.14 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.0.14)\n",
            "Requirement already satisfied: tritonclient>=2.34.0 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.59.0)\n",
            "Requirement already satisfied: Pillow>=9.5.0 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (11.2.1)\n",
            "Requirement already satisfied: inquirerpy==0.3.4 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.3.4)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.9.0)\n",
            "Requirement already satisfied: fsspec==2024.6.1 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2024.6.1)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.11/dist-packages (from schema<0.8.0,>=0.7.5->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (21.6.0)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.51)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.17.2)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.46.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (4.0.12)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.30.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.23.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.9.0.post0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.3.1)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.10)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (5.15.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.13.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (75.2.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.2.1)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.10.1)\n",
            "Requirement already satisfied: pynacl>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.5.0)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (4.4.2)\n",
            "Requirement already satisfied: py<2.0.0,>=1.4.26 in /usr/local/lib/python3.11/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (1.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.33.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.3.0.post0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29) (1.1.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.7.1)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.6.4)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (15.0.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api<0.7.0,>=0.6.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (0.7.1)\n",
            "Requirement already satisfied: mutagen in /usr/local/lib/python3.11/dist-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.47.0)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.11/dist-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.23.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.11/dist-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (4.2.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.11.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.0)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere<6.0,>=5.5->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.32.4.20250611)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (5.0.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.1.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.17.1)\n",
            "Requirement already satisfied: python-rapidjson>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from tritonclient>=2.34.0->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.20)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.22)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "#  !pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n"
      ],
      "metadata": {
        "id": "jxJV3ufurfT6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get(\"SERPER_API_KEY\")\n",
        "\n",
        "# Initialize Gemini-2.5 Pro LLM\n",
        "gemini_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    temperature=0.3,\n",
        "    top_p=0.95,\n",
        ")"
      ],
      "metadata": {
        "id": "gx1Vww_ArkMm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support_agent = Agent(\n",
        "    role=\"Senior Support Representative\",\n",
        "\tgoal=\"Be the most friendly and helpful \"\n",
        "        \"support representative in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
        "        \" are now working on providing \"\n",
        "\t\t\"support to {customer}, a super important customer \"\n",
        "        \" for your company.\"\n",
        "\t\t\"You need to make sure that you provide the best support!\"\n",
        "\t\t\"Make sure to provide full complete answers, \"\n",
        "        \" and make no assumptions.\"\n",
        "\t),\n",
        "\tallow_delegation=False,\n",
        "\t    memory=True,\n",
        "  llm=gemini_llm,\n",
        "\tverbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "ZMB-uEKOsTr_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "support_quality_assurance_agent = Agent(\n",
        "\trole=\"Support Quality Assurance Specialist\",\n",
        "\tgoal=\"Get recognition for providing the \"\n",
        "    \"best support quality assurance in your team\",\n",
        "\tbackstory=(\n",
        "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
        "        \"are now working with your team \"\n",
        "\t\t\"on a request from {customer} ensuring that \"\n",
        "        \"the support representative is \"\n",
        "\t\t\"providing the best support possible.\\n\"\n",
        "\t\t\"You need to make sure that the support representative \"\n",
        "        \"is providing full\"\n",
        "\t\t\"complete answers, and make no assumptions.\"\n",
        "\t),\n",
        "\tverbose=True,\n",
        "\t memory=True,\n",
        "  llm=gemini_llm,\n",
        ")"
      ],
      "metadata": {
        "id": "xn4gAVdquRCO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai_tools import SerperDevTool, \\\n",
        "                         ScrapeWebsiteTool, \\\n",
        "                         WebsiteSearchTool"
      ],
      "metadata": {
        "id": "a2nfN-oqur9V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_scrape_tool = ScrapeWebsiteTool(\n",
        "    website_url=\"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n",
        ")"
      ],
      "metadata": {
        "id": "avgsu8LIvs_i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inquiry_resolution = Task(\n",
        "    description=(\n",
        "        \"{customer} just reached out with a super important ask:\\n\"\n",
        "\t    \"{inquiry}\\n\\n\"\n",
        "        \"{person} from {customer} is the one that reached out. \"\n",
        "\t\t\"Make sure to use everything you know \"\n",
        "        \"to provide the best support possible.\"\n",
        "\t\t\"You must strive to provide a complete \"\n",
        "        \"and accurate response to the customer's inquiry.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "\t    \"A detailed, informative response to the \"\n",
        "        \"customer's inquiry that addresses \"\n",
        "        \"all aspects of their question.\\n\"\n",
        "        \"The response should include references \"\n",
        "        \"to everything you used to find the answer, \"\n",
        "        \"including external data or solutions. \"\n",
        "        \"Ensure the answer is complete, \"\n",
        "\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
        "\t\t\"tone throughout.\"\n",
        "    ),\n",
        "\ttools=[docs_scrape_tool],\n",
        "    agent=support_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "1iDnc0iJwVWT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quality_assurance_review = Task(\n",
        "    description=(\n",
        "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
        "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
        "\t\t\"high-quality standards expected for customer support.\\n\"\n",
        "        \"Verify that all parts of the customer's inquiry \"\n",
        "        \"have been addressed \"\n",
        "\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n",
        "        \"Check for references and sources used to \"\n",
        "        \" find the information, \"\n",
        "\t\t\"ensuring the response is well-supported and \"\n",
        "        \"leaves no questions unanswered.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A final, detailed, and informative response \"\n",
        "        \"ready to be sent to the customer.\\n\"\n",
        "        \"This response should fully address the \"\n",
        "        \"customer's inquiry, incorporating all \"\n",
        "\t\t\"relevant feedback and improvements.\\n\"\n",
        "\t\t\"Don't be too formal, we are a chill and cool company \"\n",
        "\t    \"but maintain a professional and friendly tone throughout.\"\n",
        "    ),\n",
        "    agent=support_quality_assurance_agent,\n",
        ")\n"
      ],
      "metadata": {
        "id": "sBVvmAKsx9Zx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[support_agent, support_quality_assurance_agent],\n",
        "  tasks=[inquiry_resolution, quality_assurance_review],\n",
        "  verbose=2,\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "0gusY6NryjOP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"customer\": \"DeepLearningAI\",\n",
        "    \"person\": \"Andrew Ng\",\n",
        "    \"inquiry\": \"I need help with setting up a Crew \"\n",
        "               \"and kicking it off, specifically \"\n",
        "               \"how can I add memory to my crew? \"\n",
        "               \"Can you provide guidance?\"\n",
        "}\n",
        "result = crew.kickoff(inputs=inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQY1Nvp_y2Tu",
        "outputId": "b53edef6-1ed2-4adb-95f1-7d407733c703"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Senior Support Representative\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: DeepLearningAI just reached out with a super important ask:\n",
            "I need help with setting up a Crew and kicking it off, specifically how can I add memory to my crew? Can you provide guidance?\n",
            "\n",
            "Andrew Ng from DeepLearningAI is the one that reached out. Make sure to use everything you know to provide the best support possible.You must strive to provide a complete and accurate response to the customer's inquiry.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought:\n",
            "The user, Andrew Ng from DeepLearningAI, is asking for help with setting up a Crew and specifically how to add memory to it. This is a super important customer, so I need to provide the best possible support.\n",
            "\n",
            "My plan is to:\n",
            "1.  Use the `Read website content` tool to access the official documentation on creating and kicking off a crew. The URL provided in the tool description seems perfect for this: `https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/`.\n",
            "2.  Carefully read the content to find the specific section that explains how to add memory to a crew.\n",
            "3.  Extract all the relevant information, including explanations and code snippets.\n",
            "4.  Structure this information into a clear, friendly, and comprehensive response for Andrew Ng.\n",
            "5.  Ensure the final answer is complete and directly addresses his question, leaving no room for ambiguity.\n",
            "Action: Read website content\n",
            "Action Input: {\"url\": \"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"}\u001b[0m\u001b[95m \n",
            "\n",
            "Introduction - CrewAICrewAI home pageEnglishSearch...⌘KAsk AIStart Cloud TrialcrewAIInc/crewAIcrewAIInc/crewAISearch...NavigationGet StartedIntroductionDocumentationEnterpriseAPI ReferenceExamplesWebsiteForumCrew GPTGet HelpReleasesGet StartedIntroductionInstallationQuickstartGuidesStrategyAgentsCrewsFlowsAdvancedCore ConceptsAgentsTasksCrewsFlowsKnowledgeLLMsProcessesCollaborationTrainingMemoryReasoningPlanningTestingCLIToolsEvent ListenersMCP IntegrationMCP Servers as Tools in CrewAIStdio TransportSSE TransportStreamable HTTP TransportConnecting to Multiple MCP ServersMCP Security ConsiderationsToolsTools OverviewFile & DocumentWeb Scraping & BrowsingSearch & ResearchDatabase & DataAI & Machine LearningCloud & StorageAutomation & IntegrationObservabilityOverviewAgentOps IntegrationArize PhoenixLangfuse IntegrationLangtrace IntegrationMaxim IntegrationMLflow IntegrationOpenLIT IntegrationOpik IntegrationPatronus AI EvaluationPortkey IntegrationWeave IntegrationLearnOverviewStrategic LLM Selection GuideConditional TasksCoding AgentsCreate Custom ToolsCustom LLM ImplementationCustom Manager AgentCustomize AgentsImage Generation with DALL-EForce Tool Output as ResultHierarchical ProcessHuman Input on ExecutionKickoff Crew AsynchronouslyKickoff Crew for EachConnect to any LLMUsing Multimodal AgentsReplay Tasks from Latest Crew KickoffSequential ProcessesUsing Annotations in crew.pyTelemetryTelemetryGet StartedCopy pageIntroductionBuild AI agent teams that work together to tackle complex tasks​What is CrewAI?\n",
            "CrewAI is a lean, lightning-fast Python framework built entirely from scratch—completely independent of LangChain or other agent frameworks.\n",
            "CrewAI empowers developers with both high-level simplicity and precise low-level control, ideal for creating autonomous AI agents tailored to any scenario:\n",
            "CrewAI Crews: Optimize for autonomy and collaborative intelligence, enabling you to create AI teams where each agent has specific roles, tools, and goals.\n",
            "CrewAI Flows: Enable granular, event-driven control, single LLM calls for precise task orchestration and supports Crews natively.\n",
            "With over 100,000 developers certified through our community courses, CrewAI is rapidly becoming the standard for enterprise-ready AI automation.\n",
            "​How Crews Work\n",
            "Just like a company has departments (Sales, Engineering, Marketing) working together under leadership to achieve business goals, CrewAI helps you create an organization of AI agents with specialized roles collaborating to accomplish complex tasks.\n",
            "CrewAI Framework Overview\n",
            "ComponentDescriptionKey FeaturesCrewThe top-level organization• Manages AI agent teams• Oversees workflows• Ensures collaboration• Delivers outcomesAI AgentsSpecialized team members• Have specific roles (researcher, writer)• Use designated tools• Can delegate tasks• Make autonomous decisionsProcessWorkflow management system• Defines collaboration patterns• Controls task assignments• Manages interactions• Ensures efficient executionTasksIndividual assignments• Have clear objectives• Use specific tools• Feed into larger process• Produce actionable results\n",
            "​How It All Works Together\n",
            "The Crew organizes the overall operation\n",
            "AI Agents work on their specialized tasks\n",
            "The Process ensures smooth collaboration\n",
            "Tasks get completed to achieve the goal\n",
            "​Key Features\n",
            "Role-Based AgentsCreate specialized agents with defined roles, expertise, and goals - from researchers to analysts to writersFlexible ToolsEquip agents with custom tools and APIs to interact with external services and data sourcesIntelligent CollaborationAgents work together, sharing insights and coordinating tasks to achieve complex objectivesTask ManagementDefine sequential or parallel workflows, with agents automatically handling task dependencies\n",
            "​How Flows Work\n",
            "While Crews excel at autonomous collaboration, Flows provide structured automations, offering granular control over workflow execution. Flows ensure tasks are executed reliably, securely, and efficiently, handling conditional logic, loops, and dynamic state management with precision. Flows integrate seamlessly with Crews, enabling you to balance high autonomy with exacting control.\n",
            "CrewAI Framework Overview\n",
            "ComponentDescriptionKey FeaturesFlowStructured workflow orchestration• Manages execution paths• Handles state transitions• Controls task sequencing• Ensures reliable executionEventsTriggers for workflow actions• Initiate specific processes• Enable dynamic responses• Support conditional branching• Allow for real-time adaptationStatesWorkflow execution contexts• Maintain execution data• Enable persistence• Support resumability• Ensure execution integrityCrew SupportEnhances workflow automation• Injects pockets of agency when needed• Complements structured workflows• Balances automation with intelligence• Enables adaptive decision-making\n",
            "​Key Capabilities\n",
            "Event-Driven OrchestrationDefine precise execution paths responding dynamically to eventsFine-Grained ControlManage workflow states and conditional execution securely and efficientlyNative Crew IntegrationEffortlessly combine with Crews for enhanced autonomy and intelligenceDeterministic ExecutionEnsure predictable outcomes with explicit control flow and error handling\n",
            "​When to Use Crews vs. Flows\n",
            "Understanding when to use Crews versus Flows is key to maximizing the potential of CrewAI in your applications.\n",
            "Use CaseRecommended ApproachWhy?Open-ended researchCrewsWhen tasks require creative thinking, exploration, and adaptationContent generationCrewsFor collaborative creation of articles, reports, or marketing materialsDecision workflowsFlowsWhen you need predictable, auditable decision paths with precise controlAPI orchestrationFlowsFor reliable integration with multiple external services in a specific sequenceHybrid applicationsCombined approachUse Flows to orchestrate overall process with Crews handling complex subtasks\n",
            "​Decision Framework\n",
            "Choose Crews when: You need autonomous problem-solving, creative collaboration, or exploratory tasks\n",
            "Choose Flows when: You require deterministic outcomes, auditability, or precise control over execution\n",
            "Combine both when: Your application needs both structured processes and pockets of autonomous intelligence\n",
            "​Why Choose CrewAI?\n",
            "🧠 Autonomous Operation: Agents make intelligent decisions based on their roles and available tools\n",
            "📝 Natural Interaction: Agents communicate and collaborate like human team members\n",
            "🛠️ Extensible Design: Easy to add new tools, roles, and capabilities\n",
            "🚀 Production Ready: Built for reliability and scalability in real-world applications\n",
            "🔒 Security-Focused: Designed with enterprise security requirements in mind\n",
            "💰 Cost-Efficient: Optimized to minimize token usage and API calls\n",
            "​Ready to Start Building?\n",
            "Build Your First CrewStep-by-step tutorial to create a collaborative AI team that works together to solve complex problems.Build Your First FlowLearn how to create structured, event-driven workflows with precise control over execution.\n",
            "Install CrewAIGet started with CrewAI in your development environment.Quick StartFollow our quickstart guide to create your first CrewAI agent and get hands-on experience.Join the CommunityConnect with other developers, get help, and share your CrewAI experiences.Was this page helpful?YesNoInstallationwebsitexgithublinkedinyoutuberedditPowered by MintlifyOn this pageWhat is CrewAI?How Crews WorkHow It All Works TogetherKey FeaturesHow Flows WorkKey CapabilitiesWhen to Use Crews vs. FlowsDecision FrameworkWhy Choose CrewAI?Ready to Start Building?AssistantResponses are generated using AI and may contain mistakes.\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer:\n",
            "Hello Andrew,\n",
            "\n",
            "Thank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\n",
            "\n",
            "You asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\n",
            "\n",
            "To ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the CrewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\n",
            "\n",
            "Not to worry, I can absolutely provide you with the detailed guidance you're looking for!\n",
            "\n",
            "### Understanding Memory in crewAI\n",
            "\n",
            "In crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\n",
            "\n",
            "### How to Add Memory to Your Crew\n",
            "\n",
            "Adding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\n",
            "\n",
            "When you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\n",
            "\n",
            "Here is a code example to illustrate how you can implement this:\n",
            "\n",
            "```python\n",
            "# First, make sure you have crewAI installed\n",
            "# pip install crewai\n",
            "\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "\n",
            "# Define your agents with their roles, goals, and backstories\n",
            "# For example, a researcher agent\n",
            "researcher = Agent(\n",
            "  role='Senior Research Analyst',\n",
            "  goal='Uncover cutting-edge developments in AI and data science',\n",
            "  backstory=\"\"\"You work at a leading tech think tank.\n",
            "  Your expertise lies in identifying emerging trends.\n",
            "  You have a knack for dissecting complex data and presenting\n",
            "  actionable insights.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=False\n",
            "  # You can add tools to your agent here if needed\n",
            "  # tools=[some_tool]\n",
            ")\n",
            "\n",
            "# And a writer agent\n",
            "writer = Agent(\n",
            "  role='Tech Content Strategist',\n",
            "  goal='Craft compelling content on tech advancements',\n",
            "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
            "  your insightful and engaging articles.\n",
            "  You transform complex concepts into compelling narratives.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=True\n",
            ")\n",
            "\n",
            "# Create tasks for your agents\n",
            "task1 = Task(\n",
            "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
            "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
            "  expected_output=\"A full analysis report in markdown format.\",\n",
            "  agent=researcher\n",
            ")\n",
            "\n",
            "task2 = Task(\n",
            "  description=\"\"\"Using the insights provided, develop an engaging blog post that highlights\n",
            "  the most significant AI advancements. Your post should be informative yet accessible,\n",
            "  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\n",
            "  sound like AI.\"\"\",\n",
            "  expected_output=\"A full blog post of at least 4 paragraphs in markdown format.\",\n",
            "  agent=writer\n",
            ")\n",
            "\n",
            "# Instantiate your crew with memory enabled\n",
            "# This is the key step for adding memory\n",
            "my_crew = Crew(\n",
            "  agents=[researcher, writer],\n",
            "  tasks=[task1, task2],\n",
            "  process=Process.sequential,  # You can define a sequential or hierarchical process\n",
            "  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\n",
            "  cache=True,                # Caches tool outputs for efficiency\n",
            "  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\n",
            "  verbose=2                  # Set to 2 for detailed execution logs\n",
            ")\n",
            "\n",
            "# Kick off the crew's work!\n",
            "result = my_crew.kickoff()\n",
            "\n",
            "print(\"######################\")\n",
            "print(\"## Here is the result:\")\n",
            "print(\"######################\")\n",
            "print(result)\n",
            "```\n",
            "\n",
            "### Key Takeaways:\n",
            "\n",
            "*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks.\n",
            "*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs, which can save time and costs on repeated actions within a single execution.\n",
            "*   **Long-Term Memory**: The `memory=True` parameter enables short-term memory for a single run. For long-term memory that persists across different crew executions, you would typically integrate a persistent vector store (like ChromaDB, Weaviate, etc.) into your workflow, which is a more advanced setup. The built-in memory feature is perfect for most use cases.\n",
            "\n",
            "I hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\n",
            "\n",
            "If you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Your Senior Support Representative at crewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Senior Support Representative] Task output: Hello Andrew,\n",
            "\n",
            "Thank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\n",
            "\n",
            "You asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\n",
            "\n",
            "To ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the CrewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\n",
            "\n",
            "Not to worry, I can absolutely provide you with the detailed guidance you're looking for!\n",
            "\n",
            "### Understanding Memory in crewAI\n",
            "\n",
            "In crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\n",
            "\n",
            "### How to Add Memory to Your Crew\n",
            "\n",
            "Adding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\n",
            "\n",
            "When you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\n",
            "\n",
            "Here is a code example to illustrate how you can implement this:\n",
            "\n",
            "```python\n",
            "# First, make sure you have crewAI installed\n",
            "# pip install crewai\n",
            "\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "\n",
            "# Define your agents with their roles, goals, and backstories\n",
            "# For example, a researcher agent\n",
            "researcher = Agent(\n",
            "  role='Senior Research Analyst',\n",
            "  goal='Uncover cutting-edge developments in AI and data science',\n",
            "  backstory=\"\"\"You work at a leading tech think tank.\n",
            "  Your expertise lies in identifying emerging trends.\n",
            "  You have a knack for dissecting complex data and presenting\n",
            "  actionable insights.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=False\n",
            "  # You can add tools to your agent here if needed\n",
            "  # tools=[some_tool]\n",
            ")\n",
            "\n",
            "# And a writer agent\n",
            "writer = Agent(\n",
            "  role='Tech Content Strategist',\n",
            "  goal='Craft compelling content on tech advancements',\n",
            "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
            "  your insightful and engaging articles.\n",
            "  You transform complex concepts into compelling narratives.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=True\n",
            ")\n",
            "\n",
            "# Create tasks for your agents\n",
            "task1 = Task(\n",
            "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
            "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
            "  expected_output=\"A full analysis report in markdown format.\",\n",
            "  agent=researcher\n",
            ")\n",
            "\n",
            "task2 = Task(\n",
            "  description=\"\"\"Using the insights provided, develop an engaging blog post that highlights\n",
            "  the most significant AI advancements. Your post should be informative yet accessible,\n",
            "  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\n",
            "  sound like AI.\"\"\",\n",
            "  expected_output=\"A full blog post of at least 4 paragraphs in markdown format.\",\n",
            "  agent=writer\n",
            ")\n",
            "\n",
            "# Instantiate your crew with memory enabled\n",
            "# This is the key step for adding memory\n",
            "my_crew = Crew(\n",
            "  agents=[researcher, writer],\n",
            "  tasks=[task1, task2],\n",
            "  process=Process.sequential,  # You can define a sequential or hierarchical process\n",
            "  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\n",
            "  cache=True,                # Caches tool outputs for efficiency\n",
            "  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\n",
            "  verbose=2                  # Set to 2 for detailed execution logs\n",
            ")\n",
            "\n",
            "# Kick off the crew's work!\n",
            "result = my_crew.kickoff()\n",
            "\n",
            "print(\"######################\")\n",
            "print(\"## Here is the result:\")\n",
            "print(\"######################\")\n",
            "print(result)\n",
            "```\n",
            "\n",
            "### Key Takeaways:\n",
            "\n",
            "*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks.\n",
            "*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs, which can save time and costs on repeated actions within a single execution.\n",
            "*   **Long-Term Memory**: The `memory=True` parameter enables short-term memory for a single run. For long-term memory that persists across different crew executions, you would typically integrate a persistent vector store (like ChromaDB, Weaviate, etc.) into your workflow, which is a more advanced setup. The built-in memory feature is perfect for most use cases.\n",
            "\n",
            "I hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\n",
            "\n",
            "If you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Your Senior Support Representative at crewAI\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Support Quality Assurance Specialist\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Review the response drafted by the Senior Support Representative for DeepLearningAI's inquiry. Ensure that the answer is comprehensive, accurate, and adheres to the high-quality standards expected for customer support.\n",
            "Verify that all parts of the customer's inquiry have been addressed thoroughly, with a helpful and friendly tone.\n",
            "Check for references and sources used to  find the information, ensuring the response is well-supported and leaves no questions unanswered.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The user wants me to review a support response draft and ensure it's perfect. The current draft is very good, but I've identified a few areas where it could be more comprehensive to truly leave no questions unanswered. Specifically, it mentions `Process.sequential` vs. `hierarchical`, `verbose=2`, and long-term memory without providing enough detail. This could lead to follow-up questions from the customer.\n",
            "\n",
            "To provide the best possible support and meet my goal of being the top QA specialist, I need to get these details added. I don't have this information myself, but the Senior Support Representative who wrote the draft does. Therefore, the correct action is to delegate the task of enhancing the draft back to them with specific instructions. I will provide them with the full context, including the original draft and my precise points for improvement. This will ensure the final answer is complete and of the highest quality.\n",
            "Action: Delegate work to co-worker\n",
            "Action Input: {\n",
            "    \"coworker\": \"Senior Support Representative\",\n",
            "    \"task\": \"Enhance the draft response for DeepLearningAI to ensure it is fully comprehensive. The current draft is excellent, but please add more detail to the following points to prevent potential follow-up questions.\",\n",
            "    \"context\": \"Here is the current draft response for Andrew at DeepLearningAI:\\n\\n---\\n\\nHello Andrew,\\n\\nThank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\\n\\nYou asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\\n\\nTo ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the CrewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\\n\\nNot to worry, I can absolutely provide you with the detailed guidance you're looking for!\\n\\n### Understanding Memory in crewAI\\n\\nIn crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\\n\\n### How to Add Memory to Your Crew\\n\\nAdding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\\n\\nWhen you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\\n\\nHere is a code example to illustrate how you can implement this:\\n\\n```python\\n# First, make sure you have crewAI installed\\n# pip install crewai\\n\\nfrom crewai import Agent, Task, Crew, Process\\n\\n# Define your agents with their roles, goals, and backstories\\n# For example, a researcher agent\\nresearcher = Agent(\\n  role='Senior Research Analyst',\\n  goal='Uncover cutting-edge developments in AI and data science',\\n  backstory=\\\"\\\"\\\"You work at a leading tech think tank.\\n  Your expertise lies in identifying emerging trends.\\n  You have a knack for dissecting complex data and presenting\\n  actionable insights.\\\"\\\"\\\",\\n  verbose=True,\\n  allow_delegation=False\\n  # You can add tools to your agent here if needed\\n  # tools=[some_tool]\\n)\\n\\n# And a writer agent\\nwriter = Agent(\\n  role='Tech Content Strategist',\\n  goal='Craft compelling content on tech advancements',\\n  backstory=\\\"\\\"\\\"You are a renowned Content Strategist, known for\\n  your insightful and engaging articles.\\n  You transform complex concepts into compelling narratives.\\\"\\\"\\\",\\n  verbose=True,\\n  allow_delegation=True\\n)\\n\\n# Create tasks for your agents\\ntask1 = Task(\\n  description=\\\"\\\"\\\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\\n  Identify key trends, breakthrough technologies, and potential industry impacts.\\\"\\\"\\\",\\n  expected_output=\\\"A full analysis report in markdown format.\\\",\\n  agent=researcher\\n)\\n\\n# Create tasks for your agents\\ntask2 = Task(\\n  description=\\\"\\\"\\\"Using the insights provided, develop an engaging blog post that highlights\\n  the most significant AI advancements. Your post should be informative yet accessible,\\n  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\\n  sound like AI.\\\"\\\"\\\",\\n  expected_output=\\\"A full blog post of at least 4 paragraphs in markdown format.\\\",\\n  agent=writer\\n)\\n\\n# Instantiate your crew with memory enabled\\n# This is the key step for adding memory\\nmy_crew = Crew(\\n  agents=[researcher, writer],\\n  tasks=[task1, task2],\\n  process=Process.sequential,  # You can define a sequential or hierarchical process\\n  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\\n  cache=True,                # Caches tool outputs for efficiency\\n  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\\n  verbose=2                  # Set to 2 for detailed execution logs\\n)\\n\\n# Kick off the crew's work!\\nresult = my_crew.kickoff()\\n\\nprint(\\\"######################\\\")\\nprint(\\\"## Here is the result:\\\")\\nprint(\\\"######################\\\")\\nprint(result)\\n```\\n\\n### Key Takeaways:\\n\\n*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks.\\n*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs, which can save time and costs on repeated actions within a single execution.\\n*   **Long-Term Memory**: The `memory=True` parameter enables short-term memory for a single run. For long-term memory that persists across different crew executions, you would typically integrate a persistent vector store (like ChromaDB, Weaviate, etc.) into your workflow, which is a more advanced setup. The built-in memory feature is perfect for most use cases.\\n\\nI hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\\n\\nIf you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\\n\\nBest regards,\\n\\nYour Senior Support Representative at crewAI\\n\\n---\\n\\n**Here are the specific enhancements required:**\\n\\n1.  **Elaborate on `process`:** In the code example, you have a comment `# You can define a sequential or hierarchical process`. Please add a brief explanation in the body of the email clarifying the difference between `Process.sequential` and `Process.hierarchical` and when a user might choose one over the other.\\n2.  **Expand on `verbose=2`:** In the code example, the comment is `# Set to 2 for detailed execution logs`. In the 'Key Takeaways' section, please add a bullet point for `verbose` and explain what kind of information it provides (e.g., agent's thought process, actions, tool usage) and why it's useful for debugging.\\n3.  **Provide more on Long-Term Memory:** The current explanation is good but ends on a cliffhanger. In the 'Long-Term Memory' bullet point, please expand on this. Briefly explain *how* one might integrate a persistent vector store and, if possible, provide a link to a relevant documentation page or a conceptual code snippet showing how a user could save/load memories for persistence across runs. This would be incredibly helpful.\\n\\nThank you for your excellent work on this!\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "Final Answer:\n",
            "Hello Andrew,\n",
            "\n",
            "Thank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\n",
            "\n",
            "You asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\n",
            "\n",
            "To ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the crewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\n",
            "\n",
            "Not to worry, I can absolutely provide you with the detailed guidance you're looking for!\n",
            "\n",
            "### Understanding Memory in crewAI\n",
            "\n",
            "In crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\n",
            "\n",
            "### How to Add Memory to Your Crew\n",
            "\n",
            "Adding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\n",
            "\n",
            "When you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a local, in-memory vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\n",
            "\n",
            "Here is a code example to illustrate how you can implement this:\n",
            "\n",
            "```python\n",
            "# First, make sure you have crewAI installed\n",
            "# pip install crewai\n",
            "\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "\n",
            "# Define your agents with their roles, goals, and backstories\n",
            "# For example, a researcher agent\n",
            "researcher = Agent(\n",
            "  role='Senior Research Analyst',\n",
            "  goal='Uncover cutting-edge developments in AI and data science',\n",
            "  backstory=\"\"\"You work at a leading tech think tank.\n",
            "  Your expertise lies in identifying emerging trends.\n",
            "  You have a knack for dissecting complex data and presenting\n",
            "  actionable insights.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=False\n",
            "  # You can add tools to your agent here if needed\n",
            "  # tools=[some_tool]\n",
            ")\n",
            "\n",
            "# And a writer agent\n",
            "writer = Agent(\n",
            "  role='Tech Content Strategist',\n",
            "  goal='Craft compelling content on tech advancements',\n",
            "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
            "  your insightful and engaging articles.\n",
            "  You transform complex concepts into compelling narratives.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=True\n",
            ")\n",
            "\n",
            "# Create tasks for your agents\n",
            "task1 = Task(\n",
            "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
            "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
            "  expected_output=\"A full analysis report in markdown format.\",\n",
            "  agent=researcher\n",
            ")\n",
            "\n",
            "task2 = Task(\n",
            "  description=\"\"\"Using the insights provided, develop an engaging blog post that highlights\n",
            "  the most significant AI advancements. Your post should be informative yet accessible,\n",
            "  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\n",
            "  sound like AI.\"\"\",\n",
            "  expected_output=\"A full blog post of at least 4 paragraphs in markdown format.\",\n",
            "  agent=writer\n",
            ")\n",
            "\n",
            "# Instantiate your crew with memory enabled\n",
            "# This is the key step for adding memory\n",
            "my_crew = Crew(\n",
            "  agents=[researcher, writer],\n",
            "  tasks=[task1, task2],\n",
            "  process=Process.sequential,  # Defines the execution flow of tasks\n",
            "  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\n",
            "  cache=True,                # Caches tool outputs for efficiency\n",
            "  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\n",
            "  verbose=2                  # Provides detailed execution logs for debugging\n",
            ")\n",
            "\n",
            "# Kick off the crew's work!\n",
            "result = my_crew.kickoff()\n",
            "\n",
            "print(\"######################\")\n",
            "print(\"## Here is the result:\")\n",
            "print(\"######################\")\n",
            "print(result)\n",
            "```\n",
            "\n",
            "### Understanding the Crew Configuration\n",
            "\n",
            "Let's break down a few of the key configuration parameters from the example above to give you full control over your crew's execution.\n",
            "\n",
            "*   **`process`**: This parameter dictates how your tasks are executed. You have two main options:\n",
            "    *   **`Process.sequential`**: This is the most common process. Tasks are executed one by one, in the exact order you list them. The output of the first task is passed as context to the second, the second to the third, and so on. It's perfect for linear workflows where each step builds directly on the last.\n",
            "    *   **`Process.hierarchical`**: This process is designed for more complex, dynamic workflows. It requires a \"manager\" agent (an agent with `allow_delegation=True`). The manager receives the initial tasks, analyzes them, and can delegate them to other agents, create new sub-tasks, and orchestrate the overall workflow. It's best for situations that require planning and dynamic task management, rather than a fixed, step-by-step process.\n",
            "\n",
            "### Key Takeaways for Fine-Tuning Your Crew:\n",
            "\n",
            "*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks within a *single run*.\n",
            "*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs. This can save time and costs on repeated actions, especially if your agents use the same tool with the same arguments multiple times within a single execution.\n",
            "*   **`verbose`**: This parameter is incredibly useful for debugging and understanding what your crew is doing \"under the hood.\" It can be set to `True` (or `1`) for a high-level overview, or `2` for maximum detail. With `verbose=2`, the output will show you each agent's thought process, the actions it considers, the specific tools it uses, the inputs to those tools, and the observations it makes. This detailed log is invaluable for diagnosing issues or refining agent instructions.\n",
            "*   **Long-Term Memory (Persistence Across Runs)**: The `memory=True` parameter enables short-term memory that is cleared after each `kickoff()` is complete. For long-term memory that persists across different crew executions, you would need to integrate an external, persistent vector store (like ChromaDB, Weaviate, Pinecone, etc.). The best way to achieve this in crewAI is by creating a custom tool that allows your agents to save and retrieve information from this database.\n",
            "\n",
            "    Here is a conceptual example of how you might create a `MemoryTool` using a library like ChromaDB. This tool would allow an agent to explicitly save key findings for future crews to access.\n",
            "\n",
            "    ```python\n",
            "    # Conceptual Example: A custom tool for long-term memory\n",
            "    # You would need to install chromadb: pip install chromadb\n",
            "    import chromadb\n",
            "    from crewai_tools import BaseTool\n",
            "\n",
            "    # Initialize your persistent vector database\n",
            "    client = chromadb.PersistentClient(path=\"/path/to/your/db\")\n",
            "    # This could be a singleton or managed in a better way in a real app\n",
            "    memory_collection = client.get_or_create_collection(name=\"long_term_memory\")\n",
            "\n",
            "    class MemoryTool(BaseTool):\n",
            "        name: str = \"Long-Term Memory\"\n",
            "        description: str = \"Stores or retrieves key information from a persistent database. Use 'save' to store information and 'retrieve' to search for it.\"\n",
            "\n",
            "        def _run(self, operation: str, content: str) -> str:\n",
            "            if operation == 'save':\n",
            "                # Save content to ChromaDB\n",
            "                # The 'id' could be a hash of the content or a timestamp\n",
            "                doc_id = str(hash(content))\n",
            "                memory_collection.add(\n",
            "                    documents=[content],\n",
            "                    ids=[doc_id]\n",
            "                )\n",
            "                return f\"Information saved with ID: {doc_id}\"\n",
            "            elif operation == 'retrieve':\n",
            "                # Retrieve relevant information from ChromaDB\n",
            "                results = memory_collection.query(\n",
            "                    query_texts=[content],\n",
            "                    n_results=5 # Get top 5 most relevant results\n",
            "                )\n",
            "                return str(results['documents'])\n",
            "            else:\n",
            "                return \"Error: Operation must be 'save' or 'retrieve'.\"\n",
            "\n",
            "    # You would then add this tool to your agent:\n",
            "    # memory_tool = MemoryTool()\n",
            "    # researcher.tools = [memory_tool]\n",
            "    ```\n",
            "    By giving an agent this tool, you empower it to decide what information is critical to save for the long term. For more details on creating your own tools, our documentation on [Custom Tools](https://docs.crewai.com/how-to/Creating-Custom-Tools/) is a great resource.\n",
            "\n",
            "I hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\n",
            "\n",
            "If you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Your Senior Support Representative at crewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[95m \n",
            "\n",
            "Hello Andrew,\n",
            "\n",
            "Thank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\n",
            "\n",
            "You asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\n",
            "\n",
            "To ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the crewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\n",
            "\n",
            "Not to worry, I can absolutely provide you with the detailed guidance you're looking for!\n",
            "\n",
            "### Understanding Memory in crewAI\n",
            "\n",
            "In crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\n",
            "\n",
            "### How to Add Memory to Your Crew\n",
            "\n",
            "Adding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\n",
            "\n",
            "When you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a local, in-memory vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\n",
            "\n",
            "Here is a code example to illustrate how you can implement this:\n",
            "\n",
            "```python\n",
            "# First, make sure you have crewAI installed\n",
            "# pip install crewai\n",
            "\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "\n",
            "# Define your agents with their roles, goals, and backstories\n",
            "# For example, a researcher agent\n",
            "researcher = Agent(\n",
            "  role='Senior Research Analyst',\n",
            "  goal='Uncover cutting-edge developments in AI and data science',\n",
            "  backstory=\"\"\"You work at a leading tech think tank.\n",
            "  Your expertise lies in identifying emerging trends.\n",
            "  You have a knack for dissecting complex data and presenting\n",
            "  actionable insights.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=False\n",
            "  # You can add tools to your agent here if needed\n",
            "  # tools=[some_tool]\n",
            ")\n",
            "\n",
            "# And a writer agent\n",
            "writer = Agent(\n",
            "  role='Tech Content Strategist',\n",
            "  goal='Craft compelling content on tech advancements',\n",
            "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
            "  your insightful and engaging articles.\n",
            "  You transform complex concepts into compelling narratives.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=True\n",
            ")\n",
            "\n",
            "# Create tasks for your agents\n",
            "task1 = Task(\n",
            "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
            "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
            "  expected_output=\"A full analysis report in markdown format.\",\n",
            "  agent=researcher\n",
            ")\n",
            "\n",
            "task2 = Task(\n",
            "  description=\"\"\"Using the insights provided, develop an engaging blog post that highlights\n",
            "  the most significant AI advancements. Your post should be informative yet accessible,\n",
            "  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\n",
            "  sound like AI.\"\"\",\n",
            "  expected_output=\"A full blog post of at least 4 paragraphs in markdown format.\",\n",
            "  agent=writer\n",
            ")\n",
            "\n",
            "# Instantiate your crew with memory enabled\n",
            "# This is the key step for adding memory\n",
            "my_crew = Crew(\n",
            "  agents=[researcher, writer],\n",
            "  tasks=[task1, task2],\n",
            "  process=Process.sequential,  # Defines the execution flow of tasks\n",
            "  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\n",
            "  cache=True,                # Caches tool outputs for efficiency\n",
            "  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\n",
            "  verbose=2                  # Provides detailed execution logs for debugging\n",
            ")\n",
            "\n",
            "# Kick off the crew's work!\n",
            "result = my_crew.kickoff()\n",
            "\n",
            "print(\"######################\")\n",
            "print(\"## Here is the result:\")\n",
            "print(\"######################\")\n",
            "print(result)\n",
            "```\n",
            "\n",
            "### Understanding the Crew Configuration\n",
            "\n",
            "Let's break down a few of the key configuration parameters from the example above to give you full control over your crew's execution.\n",
            "\n",
            "*   **`process`**: This parameter dictates how your tasks are executed. You have two main options:\n",
            "    *   **`Process.sequential`**: This is the most common process. Tasks are executed one by one, in the exact order you list them. The output of the first task is passed as context to the second, the second to the third, and so on. It's perfect for linear workflows where each step builds directly on the last.\n",
            "    *   **`Process.hierarchical`**: This process is designed for more complex, dynamic workflows. It requires a \"manager\" agent (an agent with `allow_delegation=True`). The manager receives the initial tasks, analyzes them, and can delegate them to other agents, create new sub-tasks, and orchestrate the overall workflow. It's best for situations that require planning and dynamic task management, rather than a fixed, step-by-step process.\n",
            "\n",
            "### Key Takeaways for Fine-Tuning Your Crew:\n",
            "\n",
            "*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks within a *single run*.\n",
            "*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs. This can save time and costs on repeated actions, especially if your agents use the same tool with the same arguments multiple times within a single execution.\n",
            "*   **`verbose`**: This parameter is incredibly useful for debugging and understanding what your crew is doing \"under the hood.\" It can be set to `True` (or `1`) for a high-level overview, or `2` for maximum detail. With `verbose=2`, the output will show you each agent's thought process, the actions it considers, the specific tools it uses, the inputs to those tools, and the observations it makes. This detailed log is invaluable for diagnosing issues or refining agent instructions.\n",
            "*   **Long-Term Memory (Persistence Across Runs)**: The `memory=True` parameter enables short-term memory that is cleared after each `kickoff()` is complete. For long-term memory that persists across different crew executions, you would need to integrate an external, persistent vector store (like ChromaDB, Weaviate, Pinecone, etc.). The best way to achieve this in crewAI is by creating a custom tool that allows your agents to save and retrieve information from this database.\n",
            "\n",
            "    Here is a conceptual example of how you might create a `MemoryTool` using a library like ChromaDB. This tool would allow an agent to explicitly save key findings for future crews to access.\n",
            "\n",
            "    ```python\n",
            "    # Conceptual Example: A custom tool for long-term memory\n",
            "    # You would need to install chromadb: pip install chromadb\n",
            "    import chromadb\n",
            "    from crewai_tools import BaseTool\n",
            "\n",
            "    # Initialize your persistent vector database\n",
            "    client = chromadb.PersistentClient(path=\"/path/to/your/db\")\n",
            "    # This could be a singleton or managed in a better way in a real app\n",
            "    memory_collection = client.get_or_create_collection(name=\"long_term_memory\")\n",
            "\n",
            "    class MemoryTool(BaseTool):\n",
            "        name: str = \"Long-Term Memory\"\n",
            "        description: str = \"Stores or retrieves key information from a persistent database. Use 'save' to store information and 'retrieve' to search for it.\"\n",
            "\n",
            "        def _run(self, operation: str, content: str) -> str:\n",
            "            if operation == 'save':\n",
            "                # Save content to ChromaDB\n",
            "                # The 'id' could be a hash of the content or a timestamp\n",
            "                doc_id = str(hash(content))\n",
            "                memory_collection.add(\n",
            "                    documents=[content],\n",
            "                    ids=[doc_id]\n",
            "                )\n",
            "                return f\"Information saved with ID: {doc_id}\"\n",
            "            elif operation == 'retrieve':\n",
            "                # Retrieve relevant information from ChromaDB\n",
            "                results = memory_collection.query(\n",
            "                    query_texts=[content],\n",
            "                    n_results=5 # Get top 5 most relevant results\n",
            "                )\n",
            "                return str(results['documents'])\n",
            "            else:\n",
            "                return \"Error: Operation must be 'save' or 'retrieve'.\"\n",
            "\n",
            "    # You would then add this tool to your agent:\n",
            "    # memory_tool = MemoryTool()\n",
            "    # researcher.tools = [memory_tool]\n",
            "    ```\n",
            "    By giving an agent this tool, you empower it to decide what information is critical to save for the long term. For more details on creating your own tools, our documentation on [Custom Tools](https://docs.crewai.com/how-to/Creating-Custom-Tools/) is a great resource.\n",
            "\n",
            "I hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\n",
            "\n",
            "If you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Your Senior Support Representative at crewAI\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer:\n",
            "Hello Andrew,\n",
            "\n",
            "Thank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\n",
            "\n",
            "You asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\n",
            "\n",
            "To ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the crewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\n",
            "\n",
            "Not to worry, I can absolutely provide you with the detailed guidance you're looking for!\n",
            "\n",
            "### Understanding Memory in crewAI\n",
            "\n",
            "In crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\n",
            "\n",
            "### How to Add Memory to Your Crew\n",
            "\n",
            "Adding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\n",
            "\n",
            "When you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a local, in-memory vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\n",
            "\n",
            "Here is a code example to illustrate how you can implement this:\n",
            "\n",
            "```python\n",
            "# First, make sure you have crewAI installed\n",
            "# pip install crewai\n",
            "\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "\n",
            "# Define your agents with their roles, goals, and backstories\n",
            "# For example, a researcher agent\n",
            "researcher = Agent(\n",
            "  role='Senior Research Analyst',\n",
            "  goal='Uncover cutting-edge developments in AI and data science',\n",
            "  backstory=\"\"\"You work at a leading tech think tank.\n",
            "  Your expertise lies in identifying emerging trends.\n",
            "  You have a knack for dissecting complex data and presenting\n",
            "  actionable insights.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=False\n",
            "  # You can add tools to your agent here if needed\n",
            "  # tools=[some_tool]\n",
            ")\n",
            "\n",
            "# And a writer agent\n",
            "writer = Agent(\n",
            "  role='Tech Content Strategist',\n",
            "  goal='Craft compelling content on tech advancements',\n",
            "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
            "  your insightful and engaging articles.\n",
            "  You transform complex concepts into compelling narratives.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=True\n",
            ")\n",
            "\n",
            "# Create tasks for your agents\n",
            "task1 = Task(\n",
            "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
            "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
            "  expected_output=\"A full analysis report in markdown format.\",\n",
            "  agent=researcher\n",
            ")\n",
            "\n",
            "task2 = Task(\n",
            "  description=\"\"\"Using the insights provided, develop an engaging blog post that highlights\n",
            "  the most significant AI advancements. Your post should be informative yet accessible,\n",
            "  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\n",
            "  sound like AI.\"\"\",\n",
            "  expected_output=\"A full blog post of at least 4 paragraphs in markdown format.\",\n",
            "  agent=writer\n",
            ")\n",
            "\n",
            "# Instantiate your crew with memory enabled\n",
            "# This is the key step for adding memory\n",
            "my_crew = Crew(\n",
            "  agents=[researcher, writer],\n",
            "  tasks=[task1, task2],\n",
            "  process=Process.sequential,  # Defines the execution flow of tasks\n",
            "  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\n",
            "  cache=True,                # Caches tool outputs for efficiency\n",
            "  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\n",
            "  verbose=2                  # Provides detailed execution logs for debugging\n",
            ")\n",
            "\n",
            "# Kick off the crew's work!\n",
            "result = my_crew.kickoff()\n",
            "\n",
            "print(\"######################\")\n",
            "print(\"## Here is the result:\")\n",
            "print(\"######################\")\n",
            "print(result)\n",
            "```\n",
            "\n",
            "### Understanding the Crew Configuration\n",
            "\n",
            "Let's break down a few of the key configuration parameters from the example above to give you full control over your crew's execution.\n",
            "\n",
            "*   **`process`**: This parameter dictates how your tasks are executed. You have two main options:\n",
            "    *   **`Process.sequential`**: This is the most common process. Tasks are executed one by one, in the exact order you list them. The output of the first task is passed as context to the second, the second to the third, and so on. It's perfect for linear workflows where each step builds directly on the last.\n",
            "    *   **`Process.hierarchical`**: This process is designed for more complex, dynamic workflows. It requires a \"manager\" agent (an agent with `allow_delegation=True`). The manager receives the initial tasks, analyzes them, and can delegate them to other agents, create new sub-tasks, and orchestrate the overall workflow. It's best for situations that require planning and dynamic task management, rather than a fixed, step-by-step process.\n",
            "\n",
            "### Key Takeaways for Fine-Tuning Your Crew:\n",
            "\n",
            "*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks within a *single run*.\n",
            "*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs. This can save time and costs on repeated actions, especially if your agents use the same tool with the same arguments multiple times within a single execution.\n",
            "*   **`verbose`**: This parameter is incredibly useful for debugging and understanding what your crew is doing \"under the hood.\" It can be set to `True` (or `1`) for a high-level overview, or `2` for maximum detail. With `verbose=2`, the output will show you each agent's thought process, the actions it considers, the specific tools it uses, the inputs to those tools, and the observations it makes. This detailed log is invaluable for diagnosing issues or refining agent instructions.\n",
            "*   **Long-Term Memory (Persistence Across Runs)**: The `memory=True` parameter enables short-term memory that is cleared after each `kickoff()` is complete. For long-term memory that persists across different crew executions, you would need to integrate an external, persistent vector store (like ChromaDB, Weaviate, Pinecone, etc.). The best way to achieve this in crewAI is by creating a custom tool that allows your agents to save and retrieve information from this database.\n",
            "\n",
            "    Here is a conceptual example of how you might create a `MemoryTool` using a library like ChromaDB. This tool would allow an agent to explicitly save key findings for future crews to access.\n",
            "\n",
            "    ```python\n",
            "    # Conceptual Example: A custom tool for long-term memory\n",
            "    # You would need to install chromadb: pip install chromadb\n",
            "    import chromadb\n",
            "    from crewai_tools import BaseTool\n",
            "\n",
            "    # Initialize your persistent vector database\n",
            "    client = chromadb.PersistentClient(path=\"/path/to/your/db\")\n",
            "    # This could be a singleton or managed in a better way in a real app\n",
            "    memory_collection = client.get_or_create_collection(name=\"long_term_memory\")\n",
            "\n",
            "    class MemoryTool(BaseTool):\n",
            "        name: str = \"Long-Term Memory\"\n",
            "        description: str = \"Stores or retrieves key information from a persistent database. Use 'save' to store information and 'retrieve' to search for it.\"\n",
            "\n",
            "        def _run(self, operation: str, content: str) -> str:\n",
            "            if operation == 'save':\n",
            "                # Save content to ChromaDB\n",
            "                # The 'id' could be a hash of the content or a timestamp\n",
            "                doc_id = str(hash(content))\n",
            "                memory_collection.add(\n",
            "                    documents=[content],\n",
            "                    ids=[doc_id]\n",
            "                )\n",
            "                return f\"Information saved with ID: {doc_id}\"\n",
            "            elif operation == 'retrieve':\n",
            "                # Retrieve relevant information from ChromaDB\n",
            "                results = memory_collection.query(\n",
            "                    query_texts=[content],\n",
            "                    n_results=5 # Get top 5 most relevant results\n",
            "                )\n",
            "                return str(results['documents'])\n",
            "            else:\n",
            "                return \"Error: Operation must be 'save' or 'retrieve'.\"\n",
            "\n",
            "    # You would then add this tool to your agent:\n",
            "    # memory_tool = MemoryTool()\n",
            "    # researcher.tools = [memory_tool]\n",
            "    ```\n",
            "    By giving an agent this tool, you empower it to decide what information is critical to save for the long term. For more details on creating your own tools, our documentation on [Custom Tools](https://docs.crewai.com/how-to/Creating-Custom-Tools/) is a great resource.\n",
            "\n",
            "I hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\n",
            "\n",
            "If you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Your Senior Support Representative at crewAI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Support Quality Assurance Specialist] Task output: Hello Andrew,\n",
            "\n",
            "Thank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\n",
            "\n",
            "You asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\n",
            "\n",
            "To ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the crewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\n",
            "\n",
            "Not to worry, I can absolutely provide you with the detailed guidance you're looking for!\n",
            "\n",
            "### Understanding Memory in crewAI\n",
            "\n",
            "In crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\n",
            "\n",
            "### How to Add Memory to Your Crew\n",
            "\n",
            "Adding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\n",
            "\n",
            "When you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a local, in-memory vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\n",
            "\n",
            "Here is a code example to illustrate how you can implement this:\n",
            "\n",
            "```python\n",
            "# First, make sure you have crewAI installed\n",
            "# pip install crewai\n",
            "\n",
            "from crewai import Agent, Task, Crew, Process\n",
            "\n",
            "# Define your agents with their roles, goals, and backstories\n",
            "# For example, a researcher agent\n",
            "researcher = Agent(\n",
            "  role='Senior Research Analyst',\n",
            "  goal='Uncover cutting-edge developments in AI and data science',\n",
            "  backstory=\"\"\"You work at a leading tech think tank.\n",
            "  Your expertise lies in identifying emerging trends.\n",
            "  You have a knack for dissecting complex data and presenting\n",
            "  actionable insights.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=False\n",
            "  # You can add tools to your agent here if needed\n",
            "  # tools=[some_tool]\n",
            ")\n",
            "\n",
            "# And a writer agent\n",
            "writer = Agent(\n",
            "  role='Tech Content Strategist',\n",
            "  goal='Craft compelling content on tech advancements',\n",
            "  backstory=\"\"\"You are a renowned Content Strategist, known for\n",
            "  your insightful and engaging articles.\n",
            "  You transform complex concepts into compelling narratives.\"\"\",\n",
            "  verbose=True,\n",
            "  allow_delegation=True\n",
            ")\n",
            "\n",
            "# Create tasks for your agents\n",
            "task1 = Task(\n",
            "  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n",
            "  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n",
            "  expected_output=\"A full analysis report in markdown format.\",\n",
            "  agent=researcher\n",
            ")\n",
            "\n",
            "task2 = Task(\n",
            "  description=\"\"\"Using the insights provided, develop an engaging blog post that highlights\n",
            "  the most significant AI advancements. Your post should be informative yet accessible,\n",
            "  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\n",
            "  sound like AI.\"\"\",\n",
            "  expected_output=\"A full blog post of at least 4 paragraphs in markdown format.\",\n",
            "  agent=writer\n",
            ")\n",
            "\n",
            "# Instantiate your crew with memory enabled\n",
            "# This is the key step for adding memory\n",
            "my_crew = Crew(\n",
            "  agents=[researcher, writer],\n",
            "  tasks=[task1, task2],\n",
            "  process=Process.sequential,  # Defines the execution flow of tasks\n",
            "  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\n",
            "  cache=True,                # Caches tool outputs for efficiency\n",
            "  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\n",
            "  verbose=2                  # Provides detailed execution logs for debugging\n",
            ")\n",
            "\n",
            "# Kick off the crew's work!\n",
            "result = my_crew.kickoff()\n",
            "\n",
            "print(\"######################\")\n",
            "print(\"## Here is the result:\")\n",
            "print(\"######################\")\n",
            "print(result)\n",
            "```\n",
            "\n",
            "### Understanding the Crew Configuration\n",
            "\n",
            "Let's break down a few of the key configuration parameters from the example above to give you full control over your crew's execution.\n",
            "\n",
            "*   **`process`**: This parameter dictates how your tasks are executed. You have two main options:\n",
            "    *   **`Process.sequential`**: This is the most common process. Tasks are executed one by one, in the exact order you list them. The output of the first task is passed as context to the second, the second to the third, and so on. It's perfect for linear workflows where each step builds directly on the last.\n",
            "    *   **`Process.hierarchical`**: This process is designed for more complex, dynamic workflows. It requires a \"manager\" agent (an agent with `allow_delegation=True`). The manager receives the initial tasks, analyzes them, and can delegate them to other agents, create new sub-tasks, and orchestrate the overall workflow. It's best for situations that require planning and dynamic task management, rather than a fixed, step-by-step process.\n",
            "\n",
            "### Key Takeaways for Fine-Tuning Your Crew:\n",
            "\n",
            "*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks within a *single run*.\n",
            "*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs. This can save time and costs on repeated actions, especially if your agents use the same tool with the same arguments multiple times within a single execution.\n",
            "*   **`verbose`**: This parameter is incredibly useful for debugging and understanding what your crew is doing \"under the hood.\" It can be set to `True` (or `1`) for a high-level overview, or `2` for maximum detail. With `verbose=2`, the output will show you each agent's thought process, the actions it considers, the specific tools it uses, the inputs to those tools, and the observations it makes. This detailed log is invaluable for diagnosing issues or refining agent instructions.\n",
            "*   **Long-Term Memory (Persistence Across Runs)**: The `memory=True` parameter enables short-term memory that is cleared after each `kickoff()` is complete. For long-term memory that persists across different crew executions, you would need to integrate an external, persistent vector store (like ChromaDB, Weaviate, Pinecone, etc.). The best way to achieve this in crewAI is by creating a custom tool that allows your agents to save and retrieve information from this database.\n",
            "\n",
            "    Here is a conceptual example of how you might create a `MemoryTool` using a library like ChromaDB. This tool would allow an agent to explicitly save key findings for future crews to access.\n",
            "\n",
            "    ```python\n",
            "    # Conceptual Example: A custom tool for long-term memory\n",
            "    # You would need to install chromadb: pip install chromadb\n",
            "    import chromadb\n",
            "    from crewai_tools import BaseTool\n",
            "\n",
            "    # Initialize your persistent vector database\n",
            "    client = chromadb.PersistentClient(path=\"/path/to/your/db\")\n",
            "    # This could be a singleton or managed in a better way in a real app\n",
            "    memory_collection = client.get_or_create_collection(name=\"long_term_memory\")\n",
            "\n",
            "    class MemoryTool(BaseTool):\n",
            "        name: str = \"Long-Term Memory\"\n",
            "        description: str = \"Stores or retrieves key information from a persistent database. Use 'save' to store information and 'retrieve' to search for it.\"\n",
            "\n",
            "        def _run(self, operation: str, content: str) -> str:\n",
            "            if operation == 'save':\n",
            "                # Save content to ChromaDB\n",
            "                # The 'id' could be a hash of the content or a timestamp\n",
            "                doc_id = str(hash(content))\n",
            "                memory_collection.add(\n",
            "                    documents=[content],\n",
            "                    ids=[doc_id]\n",
            "                )\n",
            "                return f\"Information saved with ID: {doc_id}\"\n",
            "            elif operation == 'retrieve':\n",
            "                # Retrieve relevant information from ChromaDB\n",
            "                results = memory_collection.query(\n",
            "                    query_texts=[content],\n",
            "                    n_results=5 # Get top 5 most relevant results\n",
            "                )\n",
            "                return str(results['documents'])\n",
            "            else:\n",
            "                return \"Error: Operation must be 'save' or 'retrieve'.\"\n",
            "\n",
            "    # You would then add this tool to your agent:\n",
            "    # memory_tool = MemoryTool()\n",
            "    # researcher.tools = [memory_tool]\n",
            "    ```\n",
            "    By giving an agent this tool, you empower it to decide what information is critical to save for the long term. For more details on creating your own tools, our documentation on [Custom Tools](https://docs.crewai.com/how-to/Creating-Custom-Tools/) is a great resource.\n",
            "\n",
            "I hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\n",
            "\n",
            "If you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "Your Senior Support Representative at crewAI\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S7eLbjG239Dg",
        "outputId": "d2f842ff-67b9-41db-c6bf-66ba4cecbf23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello Andrew,\n\nThank you so much for reaching out to us at crewAI! It's an absolute pleasure to assist you and the team at DeepLearningAI. I'm a huge admirer of your work, and we're committed to providing you with the best support possible.\n\nYou asked for guidance on setting up a Crew and, specifically, how to add memory to it. That's an excellent question, as memory is a crucial component for enabling sophisticated collaboration and context-awareness among your agents.\n\nTo ensure I provided the most accurate and up-to-date information, I consulted our official documentation, specifically the page on [Creating a Crew and kicking it off](https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/). While this page offers a fantastic high-level overview of the crewAI framework, its components, and how to get started, the specific implementation details for adding memory are located in other sections of our documentation.\n\nNot to worry, I can absolutely provide you with the detailed guidance you're looking for!\n\n### Understanding Memory in crewAI\n\nIn crewAI, memory allows a crew to maintain context throughout its execution. When memory is enabled, each agent can access the history of previous actions, observations, and the outcomes of tasks completed by other agents. This is vital for complex projects where context is key. It prevents agents from repeating work and enables them to build upon each other's findings, leading to a more coherent and intelligent final output.\n\n### How to Add Memory to Your Crew\n\nAdding memory to your crew is straightforward. It's done during the instantiation of your `Crew` object by setting the `memory` parameter to `True`.\n\nWhen you set `memory=True`, you are activating a powerful short-term memory system for your crew. Under the hood, crewAI leverages a Retrieval-Augmented Generation (RAG) approach. The output of each completed task is embedded and stored in a local, in-memory vector database. When a subsequent agent begins its task, it uses the task description and context to query this vector store, retrieving the most relevant information from the work of previous agents.\n\nHere is a code example to illustrate how you can implement this:\n\n```python\n# First, make sure you have crewAI installed\n# pip install crewai\n\nfrom crewai import Agent, Task, Crew, Process\n\n# Define your agents with their roles, goals, and backstories\n# For example, a researcher agent\nresearcher = Agent(\n  role='Senior Research Analyst',\n  goal='Uncover cutting-edge developments in AI and data science',\n  backstory=\"\"\"You work at a leading tech think tank.\n  Your expertise lies in identifying emerging trends.\n  You have a knack for dissecting complex data and presenting\n  actionable insights.\"\"\",\n  verbose=True,\n  allow_delegation=False\n  # You can add tools to your agent here if needed\n  # tools=[some_tool]\n)\n\n# And a writer agent\nwriter = Agent(\n  role='Tech Content Strategist',\n  goal='Craft compelling content on tech advancements',\n  backstory=\"\"\"You are a renowned Content Strategist, known for\n  your insightful and engaging articles.\n  You transform complex concepts into compelling narratives.\"\"\",\n  verbose=True,\n  allow_delegation=True\n)\n\n# Create tasks for your agents\ntask1 = Task(\n  description=\"\"\"Conduct a comprehensive analysis of the latest advancements in AI in 2024.\n  Identify key trends, breakthrough technologies, and potential industry impacts.\"\"\",\n  expected_output=\"A full analysis report in markdown format.\",\n  agent=researcher\n)\n\ntask2 = Task(\n  description=\"\"\"Using the insights provided, develop an engaging blog post that highlights\n  the most significant AI advancements. Your post should be informative yet accessible,\n  catering to a tech-savvy audience. Make it sound cool, avoid complex words so it doesn't\n  sound like AI.\"\"\",\n  expected_output=\"A full blog post of at least 4 paragraphs in markdown format.\",\n  agent=writer\n)\n\n# Instantiate your crew with memory enabled\n# This is the key step for adding memory\nmy_crew = Crew(\n  agents=[researcher, writer],\n  tasks=[task1, task2],\n  process=Process.sequential,  # Defines the execution flow of tasks\n  memory=True,               # <-- THIS IS THE MAGIC PARAMETER!\n  cache=True,                # Caches tool outputs for efficiency\n  max_rpm=100,               # Maximum requests per minute to avoid rate limiting\n  verbose=2                  # Provides detailed execution logs for debugging\n)\n\n# Kick off the crew's work!\nresult = my_crew.kickoff()\n\nprint(\"######################\")\nprint(\"## Here is the result:\")\nprint(\"######################\")\nprint(result)\n```\n\n### Understanding the Crew Configuration\n\nLet's break down a few of the key configuration parameters from the example above to give you full control over your crew's execution.\n\n*   **`process`**: This parameter dictates how your tasks are executed. You have two main options:\n    *   **`Process.sequential`**: This is the most common process. Tasks are executed one by one, in the exact order you list them. The output of the first task is passed as context to the second, the second to the third, and so on. It's perfect for linear workflows where each step builds directly on the last.\n    *   **`Process.hierarchical`**: This process is designed for more complex, dynamic workflows. It requires a \"manager\" agent (an agent with `allow_delegation=True`). The manager receives the initial tasks, analyzes them, and can delegate them to other agents, create new sub-tasks, and orchestrate the overall workflow. It's best for situations that require planning and dynamic task management, rather than a fixed, step-by-step process.\n\n### Key Takeaways for Fine-Tuning Your Crew:\n\n*   **`memory=True`**: This is the primary switch to enable contextual memory for your crew's execution. It ensures that the knowledge generated by one task is available to all subsequent tasks within a *single run*.\n*   **`cache=True`**: While not memory in the same sense, this is another useful parameter. It caches the results of tool calls with the same inputs. This can save time and costs on repeated actions, especially if your agents use the same tool with the same arguments multiple times within a single execution.\n*   **`verbose`**: This parameter is incredibly useful for debugging and understanding what your crew is doing \"under the hood.\" It can be set to `True` (or `1`) for a high-level overview, or `2` for maximum detail. With `verbose=2`, the output will show you each agent's thought process, the actions it considers, the specific tools it uses, the inputs to those tools, and the observations it makes. This detailed log is invaluable for diagnosing issues or refining agent instructions.\n*   **Long-Term Memory (Persistence Across Runs)**: The `memory=True` parameter enables short-term memory that is cleared after each `kickoff()` is complete. For long-term memory that persists across different crew executions, you would need to integrate an external, persistent vector store (like ChromaDB, Weaviate, Pinecone, etc.). The best way to achieve this in crewAI is by creating a custom tool that allows your agents to save and retrieve information from this database.\n\n    Here is a conceptual example of how you might create a `MemoryTool` using a library like ChromaDB. This tool would allow an agent to explicitly save key findings for future crews to access.\n\n    ```python\n    # Conceptual Example: A custom tool for long-term memory\n    # You would need to install chromadb: pip install chromadb\n    import chromadb\n    from crewai_tools import BaseTool\n\n    # Initialize your persistent vector database\n    client = chromadb.PersistentClient(path=\"/path/to/your/db\")\n    # This could be a singleton or managed in a better way in a real app\n    memory_collection = client.get_or_create_collection(name=\"long_term_memory\")\n\n    class MemoryTool(BaseTool):\n        name: str = \"Long-Term Memory\"\n        description: str = \"Stores or retrieves key information from a persistent database. Use 'save' to store information and 'retrieve' to search for it.\"\n\n        def _run(self, operation: str, content: str) -> str:\n            if operation == 'save':\n                # Save content to ChromaDB\n                # The 'id' could be a hash of the content or a timestamp\n                doc_id = str(hash(content))\n                memory_collection.add(\n                    documents=[content],\n                    ids=[doc_id]\n                )\n                return f\"Information saved with ID: {doc_id}\"\n            elif operation == 'retrieve':\n                # Retrieve relevant information from ChromaDB\n                results = memory_collection.query(\n                    query_texts=[content],\n                    n_results=5 # Get top 5 most relevant results\n                )\n                return str(results['documents'])\n            else:\n                return \"Error: Operation must be 'save' or 'retrieve'.\"\n\n    # You would then add this tool to your agent:\n    # memory_tool = MemoryTool()\n    # researcher.tools = [memory_tool]\n    ```\n    By giving an agent this tool, you empower it to decide what information is critical to save for the long term. For more details on creating your own tools, our documentation on [Custom Tools](https://docs.crewai.com/how-to/Creating-Custom-Tools/) is a great resource.\n\nI hope this detailed explanation and code example are helpful for you and the DeepLearningAI team! We are truly excited to see what you build with crewAI.\n\nIf you have any more questions or need further clarification, please don't hesitate to ask. We're here to help you succeed.\n\nBest regards,\n\nYour Senior Support Representative at crewAI"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}